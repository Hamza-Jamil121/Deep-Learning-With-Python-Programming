{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Lambda, Dense, Flatten,Conv2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.applications.vgg19 import VGG19\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator,load_img\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# re-size all the images to this\n",
    "IMAGE_SIZE = [224, 224]\n",
    "\n",
    "train_path = 'C:\\\\Users\\\\hamza jamil\\\\Downloads\\\\Car Brand Deep learning\\\\Deep-Learning-Car-Brand-master\\\\Datasets\\\\Train'\n",
    "valid_path = 'C:\\\\Users\\\\hamza jamil\\\\Downloads\\\\Car Brand Deep learning\\\\Deep-Learning-Car-Brand-master\\\\Datasets\\\\Test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# useful for getting number of output classes\n",
    "folders = glob('C:\\\\Users\\\\hamza jamil\\\\Downloads\\\\Car Brand Deep learning\\\\Deep-Learning-Car-Brand-master\\\\Datasets\\\\Train//*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(folders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_6 (Conv2D)            (None, 224, 224, 16)      208       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 112, 112, 16)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 112, 112, 32)      2080      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 56, 56, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 56, 56, 64)        8256      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 28, 28, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 50176)             0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 500)               25088500  \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 3)                 1503      \n",
      "=================================================================\n",
      "Total params: 25,100,547\n",
      "Trainable params: 25,100,547\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model=Sequential()\n",
    "model.add(Conv2D(filters=16,kernel_size=2,padding=\"same\",activation=\"relu\",input_shape=(224,224,3)))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Conv2D(filters=32,kernel_size=2,padding=\"same\",activation =\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Conv2D(filters=64,kernel_size=2,padding=\"same\",activation=\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(500,activation=\"relu\"))\n",
    "model.add(Dense(3,activation=\"softmax\"))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# tell the model what cost and optimization method to use\n",
    "model.compile(\n",
    "  loss='categorical_crossentropy',\n",
    "  optimizer='adam',\n",
    "  metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Use the Image Data Generator to import the images from the dataset\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 64 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "# Make sure you provide the same target size as initialied for the image size\n",
    "training_set = train_datagen.flow_from_directory('C:\\\\Users\\\\hamza jamil\\\\Downloads\\\\Car Brand Deep learning\\\\Deep-Learning-Car-Brand-master\\\\Datasets\\\\Train',\n",
    "                                                 target_size = (224, 224),\n",
    "                                                 batch_size = 32,\n",
    "                                                 class_mode = 'categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 58 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "test_set = test_datagen.flow_from_directory('C:\\\\Users\\\\hamza jamil\\\\Downloads\\\\Car Brand Deep learning\\\\Deep-Learning-Car-Brand-master\\\\Datasets\\\\Test',\n",
    "                                            target_size = (224, 224),\n",
    "                                            batch_size = 32,\n",
    "                                            class_mode = 'categorical')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1/2 [==============>...............] - ETA: 5s - loss: 1.0843 - acc: 0.4375Epoch 1/5\n",
      "2/2 [==============================] - 2s 769ms/step - loss: 19.4087 - acc: 0.1552\n",
      "2/2 [==============================] - 9s 4s/step - loss: 5.1842 - acc: 0.3750 - val_loss: 19.4087 - val_acc: 0.1552\n",
      "Epoch 2/5\n",
      "1/2 [==============>...............] - ETA: 1s - loss: 17.3339 - acc: 0.2500Epoch 1/5\n",
      "2/2 [==============================] - 1s 664ms/step - loss: 3.3909 - acc: 0.5172\n",
      "2/2 [==============================] - 5s 3s/step - loss: 12.3472 - acc: 0.3125 - val_loss: 3.3909 - val_acc: 0.5172\n",
      "Epoch 3/5\n",
      "1/2 [==============>...............] - ETA: 2s - loss: 5.5889 - acc: 0.2500Epoch 1/5\n",
      "2/2 [==============================] - 1s 706ms/step - loss: 1.4826 - acc: 0.5862\n",
      "2/2 [==============================] - 6s 3s/step - loss: 4.8963 - acc: 0.2969 - val_loss: 1.4826 - val_acc: 0.5862\n",
      "Epoch 4/5\n",
      "1/2 [==============>...............] - ETA: 1s - loss: 2.8715 - acc: 0.3125Epoch 1/5\n",
      "2/2 [==============================] - 1s 677ms/step - loss: 2.1779 - acc: 0.3276\n",
      "2/2 [==============================] - 5s 3s/step - loss: 2.7190 - acc: 0.3438 - val_loss: 2.1779 - val_acc: 0.3276\n",
      "Epoch 5/5\n",
      "1/2 [==============>...............] - ETA: 1s - loss: 2.6497 - acc: 0.4062Epoch 1/5\n",
      "2/2 [==============================] - 1s 658ms/step - loss: 1.4460 - acc: 0.3276\n",
      "2/2 [==============================] - 5s 3s/step - loss: 2.1463 - acc: 0.3906 - val_loss: 1.4460 - val_acc: 0.3276\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# fit the model\n",
    "# Run the cell. It will take some time to execute\n",
    "r = model.fit_generator(\n",
    "  training_set,\n",
    "  validation_data=test_set,\n",
    "  epochs=5,\n",
    "  steps_per_epoch=len(training_set),\n",
    "  validation_steps=len(test_set)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "model.save('Car_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.2822596 , 0.10473951, 0.6130009 ],\n",
       "       [0.30460793, 0.19206943, 0.5033226 ],\n",
       "       [0.2643293 , 0.07430949, 0.66136116],\n",
       "       [0.1619984 , 0.11931008, 0.7186915 ],\n",
       "       [0.2755844 , 0.13634738, 0.58806825],\n",
       "       [0.26982677, 0.13532555, 0.5948476 ],\n",
       "       [0.2588443 , 0.12492551, 0.61623013],\n",
       "       [0.3419012 , 0.08082566, 0.57727313],\n",
       "       [0.06843942, 0.2675825 , 0.66397804],\n",
       "       [0.3679356 , 0.12668623, 0.5053781 ],\n",
       "       [0.07925216, 0.26184422, 0.65890366],\n",
       "       [0.27216142, 0.22705144, 0.50078714],\n",
       "       [0.33085093, 0.10237906, 0.56677   ],\n",
       "       [0.2790979 , 0.12997456, 0.59092754],\n",
       "       [0.2697565 , 0.1549266 , 0.5753169 ],\n",
       "       [0.15569265, 0.12128787, 0.7230195 ],\n",
       "       [0.2504776 , 0.04806003, 0.70146227],\n",
       "       [0.23866104, 0.06388099, 0.69745797],\n",
       "       [0.25339478, 0.12693305, 0.6196721 ],\n",
       "       [0.36124623, 0.13003471, 0.508719  ],\n",
       "       [0.2086901 , 0.1222529 , 0.66905695],\n",
       "       [0.31964597, 0.07300971, 0.6073443 ],\n",
       "       [0.2694215 , 0.05463445, 0.6759441 ],\n",
       "       [0.17795423, 0.02975366, 0.7922921 ],\n",
       "       [0.31869364, 0.20948315, 0.47182325],\n",
       "       [0.12615488, 0.13889101, 0.7349542 ],\n",
       "       [0.28250504, 0.06680083, 0.65069413],\n",
       "       [0.18842356, 0.07884496, 0.7327315 ],\n",
       "       [0.28672293, 0.10652346, 0.60675365],\n",
       "       [0.16655476, 0.16330083, 0.6701444 ],\n",
       "       [0.29334667, 0.09188436, 0.614769  ],\n",
       "       [0.33765155, 0.1242143 , 0.5381342 ],\n",
       "       [0.27311066, 0.04555419, 0.6813351 ],\n",
       "       [0.2697432 , 0.12376392, 0.6064929 ],\n",
       "       [0.2766411 , 0.12350952, 0.5998494 ],\n",
       "       [0.2870361 , 0.11442406, 0.5985399 ],\n",
       "       [0.22327594, 0.19442207, 0.58230203],\n",
       "       [0.37699   , 0.1423546 , 0.48065543],\n",
       "       [0.27468082, 0.15007012, 0.5752491 ],\n",
       "       [0.28613296, 0.05682575, 0.6570413 ],\n",
       "       [0.23662764, 0.09813388, 0.6652385 ],\n",
       "       [0.21340187, 0.04753406, 0.7390641 ],\n",
       "       [0.22098926, 0.11636518, 0.6626456 ],\n",
       "       [0.25060776, 0.16782111, 0.58157116],\n",
       "       [0.29965198, 0.08560468, 0.61474335],\n",
       "       [0.2419949 , 0.0566675 , 0.70133764],\n",
       "       [0.2490358 , 0.20829378, 0.5426704 ],\n",
       "       [0.21709955, 0.09917164, 0.6837288 ],\n",
       "       [0.26873899, 0.08415574, 0.6471053 ],\n",
       "       [0.22597393, 0.16980824, 0.6042178 ],\n",
       "       [0.25164494, 0.11091796, 0.63743705],\n",
       "       [0.2682273 , 0.12714109, 0.60463166],\n",
       "       [0.20416507, 0.22467601, 0.5711589 ],\n",
       "       [0.33402735, 0.07652947, 0.5894432 ],\n",
       "       [0.30364242, 0.11369409, 0.58266354],\n",
       "       [0.15032183, 0.14988488, 0.69979334],\n",
       "       [0.28580463, 0.13064815, 0.58354723],\n",
       "       [0.24705057, 0.15467186, 0.59827757]], dtype=float32)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing import image\n",
    "modell=load_model('C:\\\\Users\\\\hamza jamil\\\\Car_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.23866104, 0.06388099, 0.69745797],\n",
       "       [0.28672293, 0.10652346, 0.60675365],\n",
       "       [0.2643293 , 0.07430949, 0.66136116],\n",
       "       [0.2490358 , 0.20829378, 0.5426704 ],\n",
       "       [0.2504776 , 0.04806003, 0.70146227],\n",
       "       [0.18842356, 0.07884496, 0.7327315 ],\n",
       "       [0.27468082, 0.15007012, 0.5752491 ],\n",
       "       [0.25060776, 0.16782111, 0.58157116],\n",
       "       [0.29965198, 0.08560468, 0.61474335],\n",
       "       [0.28250504, 0.06680083, 0.65069413],\n",
       "       [0.17795423, 0.02975366, 0.7922921 ],\n",
       "       [0.1619984 , 0.11931008, 0.7186915 ],\n",
       "       [0.36124623, 0.13003471, 0.508719  ],\n",
       "       [0.33402735, 0.07652947, 0.5894432 ],\n",
       "       [0.06843942, 0.2675825 , 0.66397804],\n",
       "       [0.2682273 , 0.12714109, 0.60463166],\n",
       "       [0.22327594, 0.19442207, 0.58230203],\n",
       "       [0.25339478, 0.12693305, 0.6196721 ],\n",
       "       [0.21340187, 0.04753406, 0.7390641 ],\n",
       "       [0.28613296, 0.05682575, 0.6570413 ],\n",
       "       [0.37699   , 0.1423546 , 0.48065543],\n",
       "       [0.16655476, 0.16330083, 0.6701444 ],\n",
       "       [0.07925216, 0.26184422, 0.65890366],\n",
       "       [0.12615488, 0.13889101, 0.7349542 ],\n",
       "       [0.22597393, 0.16980824, 0.6042178 ],\n",
       "       [0.27311066, 0.04555419, 0.6813351 ],\n",
       "       [0.2694215 , 0.05463445, 0.6759441 ],\n",
       "       [0.30460793, 0.19206943, 0.5033226 ],\n",
       "       [0.25164494, 0.11091796, 0.63743705],\n",
       "       [0.24705054, 0.15467183, 0.59827757],\n",
       "       [0.2697432 , 0.12376394, 0.6064929 ],\n",
       "       [0.30364242, 0.11369406, 0.58266354],\n",
       "       [0.26873899, 0.08415574, 0.6471053 ],\n",
       "       [0.2697565 , 0.1549266 , 0.5753169 ],\n",
       "       [0.2766411 , 0.12350952, 0.5998494 ],\n",
       "       [0.2822596 , 0.10473951, 0.6130009 ],\n",
       "       [0.2790979 , 0.12997456, 0.59092754],\n",
       "       [0.29334664, 0.09188433, 0.614769  ],\n",
       "       [0.26982677, 0.13532555, 0.5948476 ],\n",
       "       [0.20416507, 0.22467601, 0.5711589 ],\n",
       "       [0.15569265, 0.12128787, 0.7230195 ],\n",
       "       [0.33085093, 0.10237906, 0.56677   ],\n",
       "       [0.2588443 , 0.12492551, 0.61623013],\n",
       "       [0.2870361 , 0.11442406, 0.5985399 ],\n",
       "       [0.23662764, 0.09813388, 0.6652385 ],\n",
       "       [0.22098926, 0.11636518, 0.6626456 ],\n",
       "       [0.31869364, 0.20948315, 0.47182325],\n",
       "       [0.33765152, 0.1242143 , 0.5381342 ],\n",
       "       [0.28580466, 0.13064815, 0.5835472 ],\n",
       "       [0.15032183, 0.14988488, 0.69979334],\n",
       "       [0.2419949 , 0.0566675 , 0.70133764],\n",
       "       [0.27216142, 0.22705144, 0.50078714],\n",
       "       [0.2755844 , 0.13634738, 0.58806825],\n",
       "       [0.21709955, 0.09917164, 0.6837288 ],\n",
       "       [0.3679356 , 0.12668623, 0.5053781 ],\n",
       "       [0.31964597, 0.07300971, 0.6073443 ],\n",
       "       [0.3419012 , 0.08082566, 0.5772732 ],\n",
       "       [0.2086901 , 0.1222529 , 0.66905695]], dtype=float32)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modell.predict(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas.util.testing as tm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.testing import assert_frame_equal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
